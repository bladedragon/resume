/**
 * 对文段的一个简单封装
 */
const p = (left = '', right = '') => {
  return { left, right }
}
/**
 * header
 * 默认将内容转为h4
 */
const h = (left = '', right = '') => {
  return { left: `#### ${left}`, right: `#### ${right}` }
}


/**
 * 正文部分
 * 说明：本模版在pc端和打印端采用两栏式显示，手机端采用单栏
 * 请自己判断并适应页面尺寸
 */
export default [
    /**
     * 每一个小模块，都有以下几个配置项：
     * title： 顶部名称栏
     * content: 里面的内容，需要注意的是每一条内容都会换行
     */
    {
      title: '项目经历',
      content: [
        /**
         * 文章正文部分
         * left, right: 需要显示的文字，支持 b, i, a 等html标签以及一切markdown文本，请自由配置
         */
        h(`**多云离线大数据极致弹性架构建设 · 项目开发**`, ),
        // p(`- *项目简介：* 改造大数据计算底座，将大数据技术落地海外多云环境，利用云上弹性资源优势，结合内部技术演进，发挥计算优势，提高用户体验，实现降本增效。`),
        p(`- *项目简介：* 全球化多云大数据平台架构升级，基于公有云基础设施重构离线计算平台，实现混合云环境下大数据组件k8s容器化。平稳完成大数据计算平台从IDC到云原生的技术转型，接近零故障实现30%+的集群资源利用率提升，和50%+成本下降。`),
        // p(`- *项目职能：* 负责调研多家云厂商（AWS、阿里云、腾讯云、火山云）的计算集群与大数据云化解决方案，了解各家产品特性并主导对比选型，将自研技术落地三方云底座；参与<mark>离线计算组件Spark、Livy、Oflow等适配k8s</mark>, 从底层完整搭建海外大数据弹性平台，在享受云厂商的方案红利同时，充分发挥自研技术优势，为公司带来切实的成本收益。`),
        p(`- *项目职能：* 主导混合云大数据技术栈选型和POC测试，完成AWS、阿里云、腾讯云、火山云等云服务的技术评估与POC验证；负责Spark、Livy、airflow等弹性化改造，结合spot实例智能竞价策略，优化计算稳定性同时降低计算成本。主导海外离线任务迁移方案，通过实现多云引擎路由，算子级任务血缘建设等方式，保障业务迁移的稳定性`),
        h(`**Spark引擎 HBO （History-Based Optimization） · 系统优化**`, ),
        p(`- *项目简介：* 针对离线计算集群存在的资源利用率不高，毛刺较多、调度策略与真实负载匹配度低等痛点，主导设计基于作业历史信息,使用启发式策略优化作业执行的解决方案。通过级联接入层和计算层，实现作业级内存/CPU需求的动态建模，有效降低资源`),
        p(`- *项目职能：* 主导设计Spark HBO 方案，构建覆盖包含Event 解析， Stage 信息提取，真实使用内存分析的运行时数据采集管道，基于GC信息预测堆内内存使用，按需分配内存，实现真实线上作业约30%内存节省；联动接入层（例如Livy)和调度层(例如Yarn)，设计内存水位线，实现app级别的超卖和限售，在生产环境内存利用率毛刺降低， 平均利用率提升约20%；相关方案已经申请相关专利(公开号CN115617520A)`), 
        // p(`- *项目简介：* 线上较多作业参数设置存在虚位，资源利用率不高；离线作业在周期调度时的资源需求相对稳定，但是定时分配资源的策略不够灵活，也无法完全拟合实际资源使用。因为为了精细化分配作业资源，我们在接入层和计算层实现HBO，基于提交作业的历史信息建立预测模型，利用<mark>时序预测算法</mark>动态设置资源参数，优化作业资源。`),
        // p(`- *项目职能：* 负责设计和实现Spark基于HBO的优化改造。为了获取真实内存使用，上报持续引用的堆空间大小来作为当前作业真实使用堆内内存供模型预测；并通过改造动态资源分配机制实现spark按<mark>stage级别动态调整内存参数</mark>，合理申请内存，帮助实现集群资源的最大化利用。该方案已经申请相关专利(公开号CN115617520A)。`), 
        h(`**Oflow核心链路基线建设 · 项目开发**`, ),
        p(`- *项目简介：* 基于内部自研任务调度组件oflow，构建离线数据智能基线保障体系。针对跨部门数据任务依赖链路复杂（日均调度任务大于50万+）、队列资源争抢严重、核心业务保障不及时等痛点，实现核心业务链路的动态基线建模与资源分级调度，达成核心业务准点率提升10%`),
        p(`- *项目职能：* 参与设计基线智能建模架构,研发基于DAG拓扑分析的关键路径算法，实现小时级基线动态校准;构建优先级调度体系，开发动态权重分配策略，基于核心任务SLA与关键链路基线，动态生成多级优先级，驱动YARN实现资源配额动态分配；通过动态基线与分级保障，实现核心业务准点率提升10%。`),
        
        // p(`- *项目简介：* 在海外大数据上云的过程中，发现由于从hdfs转成对象存储，原生Hadoop文件提交协议的性能无法满足业务需求，因此调研了AWS S3上写入文件的最佳实践，参考了Hadoop在s3提交文件的最新进展，基于s3的特性开发了新的文件提交器：FastCommitter。`),
        // p(`- *项目职能：* 独立负责开发FastCommitter，实现过程参考了Hadoop S3ACommitter, <mark>基于S3 MultipartUpload的特点，异步上传文件块，提高了文件上传的效率</mark>；同时结合业务特性，支持Spark动态分区重写机制；相比hadoop默认文件提交器，在特定场景的提交速度可以快<mark>100%</mark>，同时s3请求数降低<mark>50%</mark>`),
        
        // p(`- *项目简介：* Shuttle是内部自研的Shuffle Service组件。向量化引擎Velox在执行Shuffle时和传统的Shuffle存在一定区别，主要由于velox基于列式数据计算，因为需要改造Shuffle Service使其实现列式shuffle。`),
        // p(`- *项目职能：* <mark>独立负责Shuffle Service适配列式Shuffle</mark>的部分。参考Gluten在Shuffle上的实现，实现了列式Shuffle的客户端，并通过JNI让Shuttle的客户端传入C++环境执行。同时结合列式计算的特殊场景，在传输上进行了优化，避免网络拥塞，保证Shuffle数据flighting时的性能。`),  
        
        // h(`**Oflow核心链路基线建设 · 项目开发**`, `[Source](https://github.com/bladedragon/JobHunter)`),
        // p(`- *项目简介：* 上游业务部门的产出依赖下游多个业务数据的支撑，这些任务存在复杂的依赖和归属关系，推动各部门分别治理成本较高且收效甚微，因此借助Oflow对全局数据的把握，从业务链路出发，设置准点基线进行重点保障`),
        // p(`- *项目职能：* 利用关键路径算法实现核心链路定位，结合历史信息预测任务执行时间，构成链路保障基线, 当任务超过基线时间时，自动通知业务负责人，实现链路高效保障;以核心链路和任务预期完成时间为基础，动态划分任务优先级，与Yarn交互实现资源的差异供给，在高峰期资源紧张时，基于任务优先级，优先满足关键业务的资源保障，保障重点数据产出。`),
      ]
    },
    {
      title: '工作经历',
      content: [
        // h('**广东OPPO移动通信有限公司 后端开发实习生** ', `*2020.07 ~ 2020.09*`),
        // p(`*实习于OPPO云平台视频云团队*，团队负责视频转码、抽帧，图片裁切等业务，主要使用Go语言开发。在实习期间，参与项目基础业务编写、质量保障，*基于红黑树实现异步任务定时器*，提高项目网络IO性能；*基于HttpAsyncClient编写异步压测工具*，方便对项目API进行压力测试`),
        h('**广东OPPO移动通信有限公司 数据平台工程师** ', `*2021.07 至今*`),
        p(`*所属互联网服务系统数据架构组*， 从事公司级底层数据平台的开发建设。`),
        p(`1. 参与开发和维护内部离线大数据任务调度系统Oflow，<mark>保障日均数万任务</mark>的正常编排调度。`),
        // h('**广东OPPO移动通信有限公司 数据平台工程师** ', `*2022.10 至今*`),
        p(`2. 参与维护和优化离线大数据计算引擎，支撑公司<mark>PB级离线数据业务</mark>。主要参与Spark计算引擎，以及自研Shuffle Service的开发工作。`),
        
      ]
    },
    {
      title: '项目经历',
      content: [
        /**
         * 文章正文部分
         * left, right: 需要显示的文字，支持 b, i, a 等html标签以及一切markdown文本，请自由配置
         */
        h(`**Shuttle 异构接入设计 · 系统优化**`, ),
        p(`- *项目简介：* 参与内部自研 Remote Shuffle Service组件Shuttle的开发工作。主导Shuttle接入架构升级，支持多引擎接入。支持MapReduce作业接入，改善云上弹性环境MR Shuffle稳定性；突破传统行式Shuffle在向量化计算场景下的性能瓶颈，实现Shuttle接入blaze向量化引擎,支撑TB级数据分析作业的稳定执行`),
        p(`- *项目职能：* 独立设计实现Shuttle的统一接入层，支持多引擎扩展；实现与向量化计算引擎blaze深度集成，基于Apache Arrow 构建jni实现rust和jvm的内存通信，开发blaze算子，实现列式数据高效转换，支持sort based shuffle；同时兼容MapReduce Shuffle， 对比未开启RSS，TB级别作业失败率下降60%，性能提升最高近1倍；`),  
        h(`**S3A FastCommitter · 系统优化**`, `[Source](http://note.zblade.top/Hadoop-CommitProtocol-jie-shao)`),
        p(`- *项目简介：* 独立实现Spark 的S3A文件提交器FastCommitter，解决了Hadoop文件系统到AWS S3对象存储中存在的提交协议性能瓶颈。调研了AWS 在S3上写入文件的最佳实践，实现基于S3A Multipart Upload协议的分块异步提交架构，在保障数据一致性的同时，支持大规模Spark作业文件提交效率提升100%，降低API 请求成本近50%`),
        p(`- *项目职能：* 独立设计S3A优化提交协议架构,参考migic committer的设计实现，结合S3 Multipart分段上传、ETag校验机制，构建零拷贝rename逻辑，实现多级缓存异步合并的分布式提交模式；结合业务特性，独立维护分区元数据，解决S3A最终一致性模型下的动态分区重写场景数据可见性问题。 `),
        // p(`- *项目简介：* Oflow是基于开源airflow改造的任务调度组件，是离线业务数据治理的入口。上游业务部门的产出依赖下游多个业务数据的支撑，这些任务存在复杂的依赖和归属关系，推动各部门分别治理成本较高且收效甚微，因此借助Oflow对全局数据的把握，从业务链路出发，设置准点基线进行重点保障`),
        // p(`- *项目职能：* 负责实现基线的确立和优先级策略的实现。利用<mark>关键路径算法</mark>实现核心链路定位，结合历史信息预测任务执行时间，构成链路保障基线；在任务执行时，<mark>动态计算关键路径</mark>，快速发现影响链路的核心任务；以核心链路和任务预期完成时间为基础，<mark>动态划分任务优先级</mark>，上报yarn实现资源的差异供给，在高峰期资源紧张时，基于任务优先级，优先满足关键业务的资源保障，保障重点数据产出。`),
      ]
    },
    
    
    {
      title: '个人能力',
      content: [
        p(`- *熟练掌握分布式系统开发技能*。熟悉Python，Java，Scala等编程语言，具备一定高并发、低延迟系统开发经验。`), 
        p(`- 熟悉大数据体系生态，熟悉数据平台的建设，拥有Spark，Hadoop, hive等大数据组件的开发经验，熟悉流批、湖仓一体技术栈，了解大数据行业前沿动态。`), 
        p(`- *具备云原生数据平台建设经验*。熟悉k8s，docker使用技能,了解公有云解决方案和多云架构设计，具备一定云上系统优化经验`), 
        p(`- *具备性能工程实践经验*。熟悉基本JVM调优技能，掌握linux系统故障排查经验`), 
        // p(`- *熟练掌握基本开发技能*。熟悉Python，Java，Scala等语言，并具有一定的实战经验，熟悉网络、IO、并发等基本原理。`), //熟悉语言
        // p(`- 拥有Spark，Hadoop yarn、hdfs, hive等大数据组件的使用经验，*熟悉Spark、Hadoop的实现。*`),    //熟悉大数据组件技术 
        // p(`- 了解大数据体系生态，熟悉数据平台的建设，了解流批一体、湖仓一体等。`),  //了解大数据生态，前沿技术，数据湖仓，流批一体
        // p(`- *具有一定云原生和大数据相结合实践经验*，熟悉k8s，docker，了解云上云下大数据产品的痛点，了解各家公有云云厂商的产品和技术。`),  //了解云原生和大数据的结合，了解公有云
        // p(`- *熟悉linux系统，具备一定的故障排查经验*，了解大数据组件常见性能指标及其优化方法`),  // 熟悉系统排查，性能指标优化
        // p(`- *时刻保持好奇心，具有持续学习钻研与创新创造精神，工作积极执行有责任心，有良好沟通协作、分析解决问题、独立思考思辨等能力。*`) //个人爱好  AI
        // p(`- *熟练掌握基本技能。* JAVA基础扎实，理解IO、多线程、集合等基础框架，对JVM有一定的理解如GC、ClassLoader机制`),
        // p('- *熟练掌握Go语言开发*，理解Go并发编程、常用框架；具有生产环境开发经验'),
        // p('- *熟悉Linux系统*，熟练运用常见的linux命令，熟悉并了解nginx相关运行原理，了解docker等工具'),
        // p('- *熟练运用MVC模式*，掌握Spring、MyBatis主流框架，并了解其运行原理；了解常见设计模式并注重代码规范和可维护性'),
        // p('- *对MySQL实战有较多开发和优化经验*，了解NoSQL相关概念，掌握Redis的基本用法'),
        // p('- *其它：* 在校担任班长，有良好的沟通能力；热爱跑步，是校田径队一员，连续两年校运会第一名，曾代表学校参加重庆市大学生运动会。喜欢探索，充满热情'),
        // p('- 日常开发环境为 macOS、VS Code，使用 Linux、Git、Markdown，默认 Google。'),
      ]
    },
    {
      title: '个人爱好',
      content: [
        p(`- 热爱运动与健身，半马4分配速`), //熟悉语言
        p(`- 喜欢摄影，剪辑和视频制作`),
        p(`- 热衷探索生成式AI和大模型产品如StableDiffusion、Sovit、ragflow等`),
      ]
    }
  
  ]
